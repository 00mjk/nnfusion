[{"tvm_func_name": "tuned_fused_convolution_op_float_i1_32_170_96_w32_32_21_11_o1_32_75_86_ws2_1_wd1_1_p0_0_kernel0", "op_type": "Convolution", "parameters": {"input_shape": [1, 32, 170, 96], "filter_shape": [32, 32, 21, 11], "output_shape": [1, 32, 75, 86], "window_movement_strides": [2, 1], "window_dilation_strides": [1, 1], "padding_below_diff": [0, 0]}, "code": "extern \"C\" __global__ void tuned_fused_convolution_op_float_i1_32_170_96_w32_32_21_11_o1_32_75_86_ws2_1_wd1_1_p0_0_kernel0( float* __restrict__ input0,  float* __restrict__ input1,  float* __restrict__ compute) {\n   float compute_local[5];\n  __shared__ float pad_temp_shared[138];\n  __shared__ float input1_shared[672];\n  #pragma unroll\n  for (int yy_c_init = 0; yy_c_init < 5; ++yy_c_init) {\n    compute_local[yy_c_init] = 0.000000e+00f;\n  }\n  for (int rc_outer = 0; rc_outer < 32; ++rc_outer) {\n    #pragma unroll\n    for (int rx_outer = 0; rx_outer < 11; ++rx_outer) {\n      __syncthreads();\n      if ((((((int)threadIdx.z) * 5) + ((int)threadIdx.x)) + ((int)threadIdx.y)) < 138) {\n        if ((((int)threadIdx.x) + ((int)threadIdx.y)) < 5) {\n          if (((int)threadIdx.x) < 1) {\n            pad_temp_shared[(((((int)threadIdx.z) * 5) + ((int)threadIdx.x)) + ((int)threadIdx.y))] = input0[((((((rc_outer * 16320) + (((int)blockIdx.y) * 4800)) + (((((((int)threadIdx.z) * 5) + ((int)threadIdx.x)) + ((int)threadIdx.y)) >> 1) * 96)) + (((int)blockIdx.x) * 2)) + rx_outer) + ((((((int)threadIdx.z) * 5) + ((int)threadIdx.x)) + ((int)threadIdx.y)) & 1))];\n          }\n        }\n      }\n      #pragma unroll\n      for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner < 3; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) {\n        if ((((((((int)threadIdx.y) * 5) + (((int)threadIdx.x) * 3)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) / 21) + ((int)threadIdx.z)) < 32) {\n          if (((((((int)threadIdx.z) * 21) + (((int)threadIdx.y) * 5)) + (((int)threadIdx.x) * 3)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) < 672) {\n            if ((((((int)threadIdx.y) * 5) + (((int)threadIdx.x) * 3)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) < 21) {\n              if (((((int)threadIdx.x) * 3) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) < 5) {\n                input1_shared[((((((int)threadIdx.z) * 21) + (((int)threadIdx.y) * 5)) + (((int)threadIdx.x) * 3)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner)] = input1[((((((((int)threadIdx.z) * 7392) + (rc_outer * 231)) + (((int)threadIdx.y) * 55)) + (((int)threadIdx.x) * 33)) + (ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner * 11)) + rx_outer)];\n              }\n            }\n          }\n        }\n      }\n      __syncthreads();\n      #pragma unroll\n      for (int ry_inner = 0; ry_inner < 21; ++ry_inner) {\n        #pragma unroll\n        for (int yy_c = 0; yy_c < 5; ++yy_c) {\n          compute_local[yy_c] = (compute_local[yy_c] + (pad_temp_shared[((((((int)threadIdx.y) * 20) + (yy_c * 4)) + (ry_inner * 2)) + ((int)threadIdx.x))] * input1_shared[((((int)threadIdx.z) * 21) + ry_inner)]));\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int yy_inner_inner_inner = 0; yy_inner_inner_inner < 5; ++yy_inner_inner_inner) {\n    compute[((((((((int)threadIdx.z) * 6450) + (((int)blockIdx.y) * 2150)) + (((int)threadIdx.y) * 430)) + (yy_inner_inner_inner * 86)) + (((int)blockIdx.x) * 2)) + ((int)threadIdx.x))] = compute_local[yy_inner_inner_inner];\n  }\n}\n\n", "gridDim": [43, 3, 1], "blockDim": [2, 5, 32]}, {"tvm_func_name": "tuned_fused_convolution_op_float_i1_1_340_181_w32_1_41_11_o1_32_150_86_ws2_2_wd1_1_p0_0_kernel0", "op_type": "Convolution", "parameters": {"input_shape": [1, 1, 340, 181], "filter_shape": [32, 1, 41, 11], "output_shape": [1, 32, 150, 86], "window_movement_strides": [2, 2], "window_dilation_strides": [1, 1], "padding_below_diff": [0, 0]}, "code": "extern \"C\" __global__ void tuned_fused_convolution_op_float_i1_1_340_181_w32_1_41_11_o1_32_150_86_ws2_2_wd1_1_p0_0_kernel0( float* __restrict__ input0,  float* __restrict__ input1,  float* __restrict__ compute) {\n   float compute_local[16];\n  __shared__ float pad_temp_shared[543];\n  __shared__ float input1_shared[88];\n  #pragma unroll\n  for (int ff_c_init = 0; ff_c_init < 2; ++ff_c_init) {\n    #pragma unroll\n    for (int xx_c_init = 0; xx_c_init < 2; ++xx_c_init) {\n      compute_local[((ff_c_init * 2) + xx_c_init)] = 0.000000e+00f;\n      compute_local[(((ff_c_init * 2) + xx_c_init) + 8)] = 0.000000e+00f;\n      compute_local[(((ff_c_init * 2) + xx_c_init) + 4)] = 0.000000e+00f;\n      compute_local[(((ff_c_init * 2) + xx_c_init) + 12)] = 0.000000e+00f;\n    }\n  }\n  for (int ry_outer = 0; ry_outer < 41; ++ry_outer) {\n    __syncthreads();\n    #pragma unroll\n    for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner < 7; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) {\n      if ((((((int)threadIdx.z) * 272) + (((int)threadIdx.x) * 7)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) < 543) {\n        if (((((int)threadIdx.x) * 7) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) < 272) {\n          pad_temp_shared[(((((int)threadIdx.z) * 272) + (((int)threadIdx.x) * 7)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner)] = input0[(((((((int)blockIdx.y) * 724) + (((int)threadIdx.z) * 272)) + (ry_outer * 181)) + (((int)threadIdx.x) * 7)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner)];\n        }\n      }\n    }\n    #pragma unroll\n    for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1 = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1 < 2; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) {\n      if (((((int)threadIdx.z) * 4) + (((((int)threadIdx.x) * 2) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) / 11)) < 8) {\n        if ((((((int)threadIdx.z) * 44) + (((int)threadIdx.x) * 2)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) < 88) {\n          if (((((int)threadIdx.x) * 2) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) < 44) {\n            input1_shared[(((((int)threadIdx.z) * 44) + (((int)threadIdx.x) * 2)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1)] = input1[(((((((int)blockIdx.z) * 3608) + (((int)threadIdx.z) * 1804)) + ((((((int)threadIdx.x) * 2) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) / 11) * 451)) + (ry_outer * 11)) + (((((int)threadIdx.x) * 2) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) % 11))];\n          }\n        }\n      }\n    }\n    __syncthreads();\n    #pragma unroll\n    for (int rx_inner = 0; rx_inner < 11; ++rx_inner) {\n      #pragma unroll\n      for (int ff_c = 0; ff_c < 2; ++ff_c) {\n        #pragma unroll\n        for (int xx_c = 0; xx_c < 2; ++xx_c) {\n          compute_local[((ff_c * 2) + xx_c)] = (compute_local[((ff_c * 2) + xx_c)] + (pad_temp_shared[(((((int)threadIdx.x) * 4) + (xx_c * 2)) + rx_inner)] * input1_shared[(((((int)threadIdx.z) * 22) + (ff_c * 11)) + rx_inner)]));\n          compute_local[(((ff_c * 2) + xx_c) + 8)] = (compute_local[(((ff_c * 2) + xx_c) + 8)] + (pad_temp_shared[(((((int)threadIdx.x) * 4) + (xx_c * 2)) + rx_inner)] * input1_shared[((((((int)threadIdx.z) * 22) + (ff_c * 11)) + rx_inner) + 44)]));\n          compute_local[(((ff_c * 2) + xx_c) + 4)] = (compute_local[(((ff_c * 2) + xx_c) + 4)] + (pad_temp_shared[((((((int)threadIdx.x) * 4) + (xx_c * 2)) + rx_inner) + 362)] * input1_shared[(((((int)threadIdx.z) * 22) + (ff_c * 11)) + rx_inner)]));\n          compute_local[(((ff_c * 2) + xx_c) + 12)] = (compute_local[(((ff_c * 2) + xx_c) + 12)] + (pad_temp_shared[((((((int)threadIdx.x) * 4) + (xx_c * 2)) + rx_inner) + 362)] * input1_shared[((((((int)threadIdx.z) * 22) + (ff_c * 11)) + rx_inner) + 44)]));\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int ff_inner_inner_inner = 0; ff_inner_inner_inner < 2; ++ff_inner_inner_inner) {\n    #pragma unroll\n    for (int xx_inner_inner_inner = 0; xx_inner_inner_inner < 2; ++xx_inner_inner_inner) {\n      compute[((((((((int)blockIdx.z) * 103200) + (((int)threadIdx.z) * 25800)) + (ff_inner_inner_inner * 12900)) + (((int)blockIdx.y) * 172)) + (((int)threadIdx.x) * 2)) + xx_inner_inner_inner)] = compute_local[((ff_inner_inner_inner * 2) + xx_inner_inner_inner)];\n      compute[(((((((((int)blockIdx.z) * 103200) + (((int)threadIdx.z) * 25800)) + (ff_inner_inner_inner * 12900)) + (((int)blockIdx.y) * 172)) + (((int)threadIdx.x) * 2)) + xx_inner_inner_inner) + 51600)] = compute_local[(((ff_inner_inner_inner * 2) + xx_inner_inner_inner) + 8)];\n      compute[(((((((((int)blockIdx.z) * 103200) + (((int)threadIdx.z) * 25800)) + (ff_inner_inner_inner * 12900)) + (((int)blockIdx.y) * 172)) + (((int)threadIdx.x) * 2)) + xx_inner_inner_inner) + 86)] = compute_local[(((ff_inner_inner_inner * 2) + xx_inner_inner_inner) + 4)];\n      compute[(((((((((int)blockIdx.z) * 103200) + (((int)threadIdx.z) * 25800)) + (ff_inner_inner_inner * 12900)) + (((int)blockIdx.y) * 172)) + (((int)threadIdx.x) * 2)) + xx_inner_inner_inner) + 51686)] = compute_local[(((ff_inner_inner_inner * 2) + xx_inner_inner_inner) + 12)];\n    }\n  }\n}\n\n", "gridDim": [1, 75, 4], "blockDim": [43, 1, 2]}]